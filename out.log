import os
import hashlib
import csv
import logging
from datetime import datetime, timedelta
from concurrent.futures import ProcessPoolExecutor, as_completed

# Configure logging
logging.basicConfig(filename='file_hashing.log', level=logging.DEBUG,
                    format='%(asctime)s - %(levelname)s - %(message)s')

def get_folder_path(prompt):
    while True:
        folder_path = input(prompt)
        if os.path.isdir(folder_path):
            return folder_path
        else:
            print("The folder does not exist. Please try again.")
            logging.error("The folder does not exist: %s", folder_path)

def get_output_path(prompt):
    while True:
        output_path = input(prompt)
        if os.path.isdir(os.path.dirname(output_path)):
            return output_path
        else:
            print("The output folder does not exist. Please try again.")
            logging.error("The output folder does not exist: %s", os.path.dirname(output_path))

def hash_file(file_path):
    sha256_hash = hashlib.sha256()
    try:
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(8192), b""):
                sha256_hash.update(byte_block)
        return file_path, sha256_hash.hexdigest()
    except Exception as e:
        logging.error("Error hashing file %s: %s", file_path, e)
        return file_path, None

def hash_files_in_folder(folder):
    files_to_hash = []
    for root, dirs, files in os.walk(folder):
        for file in files:
            files_to_hash.append(os.path.join(root, file))

    hash_results = {}
    start_time = datetime.now()
    total_files = len(files_to_hash)

    with ProcessPoolExecutor() as executor:
        future_to_file = {executor.submit(hash_file, file): file for file in files_to_hash}
        for idx, future in enumerate(as_completed(future_to_file), 1):
            file_path, file_hash = future.result()
            if file_hash:
                hash_results[file_path] = file_hash

            # Update progress
            elapsed_time = datetime.now() - start_time
            avg_time_per_file = elapsed_time / idx
            remaining_files = total_files - idx
            estimated_remaining_time = avg_time_per_file * remaining_files

            print(f"Processed {idx}/{total_files} files. "
                  f"Elapsed time: {elapsed_time}, "
                  f"Estimated remaining time: {estimated_remaining_time}")

    return hash_results

def compare_hashes(source_folder, destination_folder):
    # Hash files in source and destination folders
    source_hashes = hash_files_in_folder(source_folder)
    destination_hashes = hash_files_in_folder(destination_folder)

    # Compare hashes
    differences = []
    for file_path, source_hash in source_hashes.items():
        relative_path = os.path.relpath(file_path, source_folder)
        destination_file_path = os.path.join(destination_folder, relative_path)
        destination_hash = destination_hashes.get(destination_file_path)

        if destination_hash is None:
            differences.append((relative_path, source_hash, "MISSING"))
        elif source_hash != destination_hash:
            differences.append((relative_path, source_hash, destination_hash))

    return differences

def main():
    logging.info("Program started.")
    start_time = datetime.now()

    source_folder = get_folder_path("Enter the source folder containing the files to hash: ")
    destination_folder = get_folder_path("Enter the destination folder containing the files to hash: ")
    output_csv = get_output_path("Enter the full path for the output CSV file: ")

    differences = compare_hashes(source_folder, destination_folder)

    try:
        with open(output_csv, 'w', newline='') as csvfile:
            csvwriter = csv.writer(csvfile)
            csvwriter.writerow(['Relative Path', 'Source Hash', 'Destination Hash'])

            for difference in differences:
                csvwriter.writerow(difference)

        logging.info("Hash comparison results have been written to %s", output_csv)
    except Exception as e:
        logging.error("Error writing to CSV file %s: %s", output_csv, e)

    end_time = datetime.now()
    processing_time = end_time - start_time
    logging.info("Program finished. Processing time: %s", processing_time)
    print(f"Hash comparison results have been written to {output_csv}")

if __name__ == "__main__":
    main()



import os
import hashlib
import csv
import logging
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import psutil
import time

# Configure logging
logging.basicConfig(filename='file_hashing.log', level=logging.DEBUG,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# Define the number of worker threads
MAX_WORKERS = 40  # Increase number of threads for I/O-bound tasks

def get_folder_path(prompt):
    while True:
        folder_path = input(prompt)
        if os.path.isdir(folder_path):
            return folder_path
        else:
            print("The folder does not exist. Please try again.")
            logging.error("The folder does not exist: %s", folder_path)

def get_output_path(prompt):
    while True:
        output_path = input(prompt)
        if os.path.isdir(os.path.dirname(output_path)):
            return output_path
        else:
            print("The output folder does not exist. Please try again.")
            logging.error("The output folder does not exist: %s", os.path.dirname(output_path))

def hash_file(file_path):
    sha256_hash = hashlib.sha256()
    try:
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(65536), b""):  # Read in larger chunks
                sha256_hash.update(byte_block)
        return file_path, sha256_hash.hexdigest()
    except Exception as e:
        logging.error("Error hashing file %s: %s", file_path, e)
        return file_path, None

def hash_files_in_folder(folder):
    files_to_hash = []
    for root, dirs, files in os.walk(folder):
        for file in files:
            files_to_hash.append(os.path.join(root, file))

    hash_results = {}
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {executor.submit(hash_file, file): file for file in files_to_hash}
        for future in as_completed(future_to_file):
            file_path, file_hash = future.result()
            if file_hash:
                hash_results[file_path] = file_hash

    return hash_results

def compare_hashes(source_folder, destination_folder):
    # Hash files in source and destination folders
    source_hashes = hash_files_in_folder(source_folder)
    destination_hashes = hash_files_in_folder(destination_folder)

    # Compare hashes
    differences = []
    for file_path, source_hash in source_hashes.items():
        relative_path = os.path.relpath(file_path, source_folder)
        destination_file_path = os.path.join(destination_folder, relative_path)
        destination_hash = destination_hashes.get(destination_file_path)

        if destination_hash is None:
            differences.append((relative_path, source_hash, "MISSING"))
        elif source_hash != destination_hash:
            differences.append((relative_path, source_hash, destination_hash))

    return differences

def monitor_resources(interval=1):
    try:
        while True:
            cpu_usage = psutil.cpu_percent(interval=interval)
            memory_info = psutil.virtual_memory()
            memory_usage = memory_info.percent
            thread_count = threading.active_count()
            logging.info(f"CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%, Active Threads: {thread_count}")
            print(f"CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%, Active Threads: {thread_count}")
    except KeyboardInterrupt:
        print("Monitoring stopped.")

def main():
    logging.info("Program started.")
    start_time = datetime.now()

    source_folder = get_folder_path("Enter the source folder containing the files to hash: ")
    destination_folder = get_folder_path("Enter the destination folder containing the files to hash: ")
    output_csv = get_output_path("Enter the full path for the output CSV file: ")

    # Start resource monitoring in a separate thread
    monitor_thread = threading.Thread(target=monitor_resources)
    monitor_thread.daemon = True
    monitor_thread.start()

    differences = compare_hashes(source_folder, destination_folder)

    try:
        with open(output_csv, 'w', newline='') as csvfile:
            csvwriter = csv.writer(csvfile)
            csvwriter.writerow(['Relative Path', 'Source Hash', 'Destination Hash'])

            for difference in differences:
                csvwriter.writerow(difference)

        logging.info("Hash comparison results have been written to %s", output_csv)
    except Exception as e:
        logging.error("Error writing to CSV file %s: %s", output_csv, e)

    end_time = datetime.now()
    processing_time = end_time - start_time
    logging.info("Program finished. Processing time: %s", processing_time)
    print(f"Hash comparison results have been written to {output_csv}")

if __name__ == "__main__":
    main()

import csv
import os

def read_hashes_from_csv(csv_file):
    """Read file hashes from a CSV file and return as a dictionary."""
    file_hashes = {}
    try:
        with open(csv_file, mode='r', newline='') as f:
            reader = csv.DictReader(f)
            for row in reader:
                file_hashes[row['file_path']] = row['file_hash']
    except Exception as e:
        print(f"Error reading {csv_file}: {e}")
    return file_hashes

def convert_to_relative_paths(file_hashes, base_path):
    """Convert file paths in the dictionary to relative paths."""
    relative_file_hashes = {}
    for file_path, file_hash in file_hashes.items():
        relative_path = os.path.relpath(file_path, base_path)
        relative_file_hashes[relative_path] = file_hash
    return relative_file_hashes

def compare_hashes(source_hashes, destination_hashes):
    """Compare two dictionaries of file hashes and return differences."""
    missing_in_destination = []
    different_hashes = []
    
    # Check for files missing in destination or with different hashes
    for file_path, src_hash in source_hashes.items():
        dest_hash = destination_hashes.get(file_path)
        if dest_hash is None:
            missing_in_destination.append(file_path)
        elif dest_hash != src_hash:
            different_hashes.append((file_path, src_hash, dest_hash))
    
    # Check for files present in destination but missing in source
    extra_in_destination = [file_path for file_path in destination_hashes if file_path not in source_hashes]

    return missing_in_destination, different_hashes, extra_in_destination

def save_comparison_results(missing_in_destination, different_hashes, extra_in_destination, output_csv):
    """Save the comparison results to a CSV file."""
    try:
        with open(output_csv, mode='w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['File Path', 'Source Hash', 'Destination Hash', 'Status'])

            for file_path in missing_in_destination:
                writer.writerow([file_path, '', '', 'Missing in Destination'])
            
            for file_path, src_hash, dest_hash in different_hashes:
                writer.writerow([file_path, src_hash, dest_hash, 'Different Hashes'])
            
            for file_path in extra_in_destination:
                writer.writerow([file_path, '', '', 'Extra in Destination'])
        
        print(f"Comparison results have been saved to {output_csv}")
    except Exception as e:
        print(f"Error saving comparison results: {e}")

def main():
    source_csv = input("Enter the path to the source CSV file: ")
    destination_csv = input("Enter the path to the destination CSV file: ")
    output_csv = input("Enter the path to save the comparison results CSV file: ")
    source_base_path = input("Enter the base path for the source files: ")
    destination_base_path = input("Enter the base path for the destination files: ")

    source_hashes = read_hashes_from_csv(source_csv)
    destination_hashes = read_hashes_from_csv(destination_csv)
    
    # Convert to relative paths
    source_hashes = convert_to_relative_paths(source_hashes, source_base_path)
    destination_hashes = convert_to_relative_paths(destination_hashes, destination_base_path)
    
    missing_in_destination, different_hashes, extra_in_destination = compare_hashes(source_hashes, destination_hashes)
    
    if missing_in_destination:
        print("Files missing in destination:")
        for file_path in missing_in_destination:
            print(file_path)
    
    if different_hashes:
        print("\nFiles with different hashes:")
        for file_path, src_hash, dest_hash in different_hashes:
            print(f"{file_path}\n Source Hash: {src_hash}\n Destination Hash: {dest_hash}")
    
    if extra_in_destination:
        print("\nExtra files in destination:")
        for file_path in extra_in_destination:
            print(file_path)
    
    if not missing_in_destination and not different_hashes and not extra_in_destination:
        print("The source and destination hashes are identical.")

    # Save results to CSV
    save_comparison_results(missing_in_destination, different_hashes, extra_in_destination, output_csv)

if __name__ == "__main__":
    main()


